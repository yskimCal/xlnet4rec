{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XLNet4Rec_Movelense1M.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Do7lTmrzffcm"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpXx4aMjAI4v"
      },
      "source": [
        "#XLNet4Rec - Movielense 1M"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKGco8Y6ASaN"
      },
      "source": [
        "#### References: \n",
        "<br> 1) Tokenization and embedding\n",
        "* https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313\n",
        "* https://reyfarhan.com/posts/easy-gpt2-finetuning-huggingface/\n",
        "\n",
        "<br> 2) Training and Testing\n",
        "* https://mccormickml.com/2019/09/19/XLNet-fine-tuning/\n",
        "* https://towardsdatascience.com/teaching-gpt-2-a-sense-of-humor-fine-tuning-large-transformer-models-on-a-single-gpu-in-pytorch-59e8cec40912\n",
        "* https://huggingface.co/transformers/model_doc/xlnet.html\n",
        "\n",
        "<br> 3) Evaluation\n",
        "* https://github.com/FeiSun/BERT4Rec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ7bsUXOAT7y"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu7aM8vk_yU1"
      },
      "source": [
        "# Install transformers\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBf2UDALAW0L"
      },
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import io\n",
        "import pickle\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "\n",
        "import sklearn\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import BertTokenizer, XLNetTokenizer, XLNetConfig, XLNetModel, XLNetLMHeadModel \n",
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtIzyHo8AZJq",
        "outputId": "e1e254ea-9098-406d-cd09-80e380c9dcdf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-YVWHLbA917"
      },
      "source": [
        "ratings_frame = pd.read_csv(F\"/content/gdrive/My Drive/ML_1m/ratings.dat\", names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"], sep=\"::\", engine=\"python\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKX-6jieLenr"
      },
      "source": [
        "ratings_frame.movieId = ratings_frame.movieId.apply(str)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKVtbFfDBMtU"
      },
      "source": [
        "# Find users with more than 5 ratings\n",
        "idlist = ratings_frame['userId'].value_counts()\n",
        "indexes = idlist[idlist >= 5].index"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFlZOCiiRATm"
      },
      "source": [
        "# Extract Popular items\n",
        "pdlist = ratings_frame['movieId'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJzJ9zR9RGrg"
      },
      "source": [
        "# Combine users and ratings as a list\n",
        "ratings_subset = ratings_frame[ratings_frame['userId'].isin(indexes)]\n",
        "ratings_subset.sort_values(by=['userId', 'timestamp'], inplace = True)\n",
        "ratings_final = ratings_subset.groupby('userId')['movieId'].apply(list).reset_index(name='items')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "3mrEpb24RTR4",
        "outputId": "b4cf44d2-8f11-464b-e208-54c3cfe8c0a5"
      },
      "source": [
        "ratings_final"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>items</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[3186, 1270, 1721, 1022, 2340, 1836, 3408, 280...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[1198, 1210, 1217, 2717, 1293, 2943, 1225, 119...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[593, 2858, 3534, 1968, 1431, 1961, 1266, 1378...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[1210, 1097, 3468, 480, 3527, 260, 1196, 1198,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[2717, 908, 919, 1250, 356, 2858, 1127, 2188, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6035</th>\n",
              "      <td>6036</td>\n",
              "      <td>[1721, 2428, 3438, 1883, 2376, 2492, 2826, 282...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6036</th>\n",
              "      <td>6037</td>\n",
              "      <td>[1882, 3508, 702, 1267, 2028, 3148, 858, 562, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6037</th>\n",
              "      <td>6038</td>\n",
              "      <td>[920, 3396, 1210, 2146, 356, 1387, 1079, 1148,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6038</th>\n",
              "      <td>6039</td>\n",
              "      <td>[282, 111, 2067, 930, 1230, 3022, 947, 3088, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039</th>\n",
              "      <td>6040</td>\n",
              "      <td>[858, 593, 2384, 1961, 2019, 573, 1419, 213, 3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6040 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      userId                                              items\n",
              "0          1  [3186, 1270, 1721, 1022, 2340, 1836, 3408, 280...\n",
              "1          2  [1198, 1210, 1217, 2717, 1293, 2943, 1225, 119...\n",
              "2          3  [593, 2858, 3534, 1968, 1431, 1961, 1266, 1378...\n",
              "3          4  [1210, 1097, 3468, 480, 3527, 260, 1196, 1198,...\n",
              "4          5  [2717, 908, 919, 1250, 356, 2858, 1127, 2188, ...\n",
              "...      ...                                                ...\n",
              "6035    6036  [1721, 2428, 3438, 1883, 2376, 2492, 2826, 282...\n",
              "6036    6037  [1882, 3508, 702, 1267, 2028, 3148, 858, 562, ...\n",
              "6037    6038  [920, 3396, 1210, 2146, 356, 1387, 1079, 1148,...\n",
              "6038    6039  [282, 111, 2067, 930, 1230, 3022, 947, 3088, 3...\n",
              "6039    6040  [858, 593, 2384, 1961, 2019, 573, 1419, 213, 3...\n",
              "\n",
              "[6040 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "Es0NDk3RRUdp",
        "outputId": "5e14c999-1c77-46a2-804e-ef5483d8f678"
      },
      "source": [
        "# Check length of items per user\n",
        "import seaborn as sns\n",
        "\n",
        "item_lengths = []\n",
        "\n",
        "for r in range(0,len(ratings_final['items'])):\n",
        "\n",
        "    # get rough token count distribution\n",
        "    item_lengths.append(len(ratings_final['items'][r]))\n",
        "\n",
        "doc_lengths = np.array(item_lengths)\n",
        "\n",
        "sns.distplot(item_lengths)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fabdcf706d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vhxl-lXRZLh",
        "outputId": "58f24e31-8f2f-43e3-80fc-ac8de78a838e"
      },
      "source": [
        "# Maximum length of items\n",
        "np.max(item_lengths)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MBqBugNRdLJ",
        "outputId": "57249219-36d3-48e2-fcee-64e169898641"
      },
      "source": [
        "# Median length of items\n",
        "np.mean(item_lengths)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "165.5975165562914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I82ewOO1Rhwv",
        "outputId": "197d2ef1-c607-4305-9cc3-355c0de3a86a"
      },
      "source": [
        "# Length of final dataset\n",
        "len(ratings_final)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6040"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NCaBcayRjiT"
      },
      "source": [
        "# Create new tokens\n",
        "from itertools import chain\n",
        "#new_tokens = list(set(list(chain(*ratings_final['items']))))\n",
        "new_tokens = list(pdlist.index)\n",
        "#new_tokens = ['<unk>','<s>','</s>','<cls>','<sep>','<pad>','<mask>','<eod>','<eop>'] + new_tokens\n",
        "new_tokens = ['<unk>','<mask>','<pad>','<cls>','<sep>'] + new_tokens"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOuSFyH-RlQ5",
        "outputId": "f5f8d9e5-c267-4cd9-ddf9-c2a8ab087e26"
      },
      "source": [
        "# Length of new tokens\n",
        "len(new_tokens)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3711"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsPHRMNbRmVC"
      },
      "source": [
        "# Create vocab list for tokenizer\n",
        "with open('vocab.txt', 'w') as f:\n",
        "    for item in new_tokens:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lztPsT4dRpUz"
      },
      "source": [
        "# Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6YZjfp1RnUp"
      },
      "source": [
        "# Tokenizer\n",
        "tokenizer = BertTokenizer(vocab_file='vocab.txt', unk_token='<unk>', do_lower_case=False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmFC7wIWRvsS"
      },
      "source": [
        "# Padding function\n",
        "max_length=200\n",
        "# Now we can pad reply and distractor inputs and targets to the same length\n",
        "def pad(x, padding):\n",
        "    return x + [padding] * (max_length - len(x))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrYfNm0ZRwri"
      },
      "source": [
        "# Prepare item seq and padding function\n",
        "item_seq = ratings_final['items']\n",
        "train = []\n",
        "val = []\n",
        "test = []\n",
        "\n",
        "for i in range(0,len(item_seq)):\n",
        "  if len(item_seq[i]) > max_length:\n",
        "    seq = item_seq[i][0:max_length]\n",
        "  else:\n",
        "    seq = item_seq[i]\n",
        "  train.append(seq[0:-2])\n",
        "  val.append(seq[0:-1])\n",
        "  test.append(seq)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3no0R6XRxjD"
      },
      "source": [
        "# Class for creating dataset\n",
        "class XLNetDataset(Dataset):\n",
        "\n",
        "  def __init__(self, item_seq, tokenizer, max_length=50):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.lables = []\n",
        "    #self.perm_mask = []\n",
        "    self.target_mapping = []\n",
        "    \n",
        "    for seq in item_seq: \n",
        "      if len(seq) == max_length:\n",
        "        seq = seq[0:-2]\n",
        "      elif len(seq) == (max_length-1):\n",
        "        seq = seq[0:-1]\n",
        "      else:\n",
        "        seq = seq\n",
        "      tokens = seq + ['<sep>'] + ['<cls>'] \n",
        "\n",
        "      # words token\n",
        "      input_words = tokenizer.convert_tokens_to_ids(tokens)\n",
        "      input_words = pad(input_words, 2)\n",
        "      words = torch.tensor(input_words, dtype=torch.long)\n",
        "      assert len(words) == max_length\n",
        "\n",
        "      # lables\n",
        "      lables = words[torch.where(words == 4)[0]-1]\n",
        "      self.lables.append(lables)\n",
        "\n",
        "      '''\n",
        "      # perm_mask\n",
        "      perm_mask = torch.zeros((1, words.shape[0], words.shape[0]), dtype=torch.long)\n",
        "      perm_mask[:, :, torch.where(words == 4)[0]-1] = 1\n",
        "      self.perm_mask.append(perm_mask[0])\n",
        "      '''\n",
        "      # target mapping\n",
        "      target_mapping = torch.zeros((1, 1, words.shape[0]), dtype=torch.float)\n",
        "      target_mapping[0, 0, torch.where(words == 4)[0]-1] = 1\n",
        "      self.target_mapping.append(target_mapping[0])\n",
        "\n",
        "      # masking\n",
        "      words[torch.where(words == 4)[0]-1] = 1\n",
        "      self.input_ids.append(words)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.lables[idx], self.target_mapping[idx], #self.perm_mask[idx], "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9EfVp9ZRyuy"
      },
      "source": [
        "# Create Dataset\n",
        "#dataset = XLNetDataset(item_seq, tokenizer, max_length=200)\n",
        "train_dataset = XLNetDataset(train, tokenizer, max_length=200)\n",
        "val_dataset = XLNetDataset(val, tokenizer, max_length=200)\n",
        "test_dataset = XLNetDataset(test, tokenizer, max_length=200)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7ygqSXeURyL"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgGtZmP7USeu"
      },
      "source": [
        "batch_size = 2\n",
        "\n",
        "# Create the DataLoaders for our training and validation datasets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = SequentialSampler(train_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = 1 # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "# Test\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset, # The test samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TcYlAYHUUrw"
      },
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifRTN1NiUZDX"
      },
      "source": [
        "config = XLNetConfig(\n",
        "    vocab_size=3711\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz1F4JH_UjIQ"
      },
      "source": [
        "model = XLNetLMHeadModel(config=config)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZUftVJCUmNO"
      },
      "source": [
        "BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "WARMUP_STEPS = 100\n",
        "MAX_SEQ_LEN = 200\n",
        "total_steps = len(train_dataloader) * EPOCHS"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-v976HuUpdJ",
        "outputId": "dcaaf72c-d241-499d-dfb3-9f82f4710a12"
      },
      "source": [
        "%%time\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_steps ,last_epoch = -1)\n",
        "proc_seq_count = 0\n",
        "sum_loss = 0.0\n",
        "batch_count = 0\n",
        "\n",
        "models_folder = \"trained_models\"\n",
        "if not os.path.exists(models_folder):\n",
        "    os.mkdir(models_folder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    print(f\"EPOCH {epoch} started\" + '=' * 30)\n",
        "    \n",
        "    for idx, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "        b_target_mapping = batch[2].to(device)\n",
        "        \n",
        "        outputs = model(input_ids=b_input_ids, labels=b_labels, target_mapping=b_target_mapping)\n",
        "\n",
        "        loss, logits = outputs[:2]                        \n",
        "        loss.backward()\n",
        "        sum_loss = sum_loss + loss.detach().data\n",
        "                       \n",
        "        proc_seq_count = proc_seq_count + 1\n",
        "        if proc_seq_count == BATCH_SIZE:\n",
        "            proc_seq_count = 0    \n",
        "            batch_count += 1\n",
        "            optimizer.step()\n",
        "            scheduler.step() \n",
        "            optimizer.zero_grad()\n",
        "            model.zero_grad()\n",
        "\n",
        "        if batch_count == 100:\n",
        "            print(f\"sum loss {sum_loss}\")\n",
        "            batch_count = 0\n",
        "            sum_loss = 0.0\n",
        "    \n",
        "    # Store the model after each epoch to compare the performance of them\n",
        "    torch.save(model.state_dict(), os.path.join(models_folder, f\"XLNet4Rec_Movie_{epoch}.pt\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 0 started==============================\n",
            "sum loss 1647.1646728515625\n",
            "sum loss 1607.5379638671875\n",
            "sum loss 1614.858154296875\n",
            "sum loss 1625.7506103515625\n",
            "sum loss 1628.0137939453125\n",
            "sum loss 1603.4366455078125\n",
            "sum loss 1585.4676513671875\n",
            "sum loss 1571.197021484375\n",
            "sum loss 1581.832763671875\n",
            "sum loss 1588.564453125\n",
            "sum loss 1597.232666015625\n",
            "sum loss 1605.02880859375\n",
            "sum loss 1594.077392578125\n",
            "sum loss 1603.5548095703125\n",
            "sum loss 1579.5252685546875\n",
            "CPU times: user 15min 51s, sys: 8min 25s, total: 24min 17s\n",
            "Wall time: 24min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8B5ldi0VTsr"
      },
      "source": [
        "model_save_name = 'XLNet4Rec_Movie_1.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do7lTmrzffcm"
      },
      "source": [
        "# Another Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1WTK2XMfio6",
        "outputId": "e549940f-412b-4b46-8774-9fb7a13fbaa6"
      },
      "source": [
        "model_save_name = 'XLNet4Rec_Movie_3.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnMHS4jZfhDv",
        "outputId": "a4cca49b-2326-4f5b-cd78-ca8a9c45d870"
      },
      "source": [
        "%%time\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_steps ,last_epoch = -1)\n",
        "proc_seq_count = 0\n",
        "sum_loss = 0.0\n",
        "batch_count = 0\n",
        "\n",
        "models_folder = \"trained_models\"\n",
        "if not os.path.exists(models_folder):\n",
        "    os.mkdir(models_folder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    print(f\"EPOCH {epoch} started\" + '=' * 30)\n",
        "    \n",
        "    for idx, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "        b_target_mapping = batch[2].to(device)\n",
        "        \n",
        "        outputs = model(input_ids=b_input_ids, labels=b_labels, target_mapping=b_target_mapping)\n",
        "\n",
        "        loss, logits = outputs[:2]                        \n",
        "        loss.backward()\n",
        "        sum_loss = sum_loss + loss.detach().data\n",
        "                       \n",
        "        proc_seq_count = proc_seq_count + 1\n",
        "        if proc_seq_count == BATCH_SIZE:\n",
        "            proc_seq_count = 0    \n",
        "            batch_count += 1\n",
        "            optimizer.step()\n",
        "            scheduler.step() \n",
        "            optimizer.zero_grad()\n",
        "            model.zero_grad()\n",
        "\n",
        "        if batch_count == 100:\n",
        "            print(f\"sum loss {sum_loss}\")\n",
        "            batch_count = 0\n",
        "            sum_loss = 0.0\n",
        "    \n",
        "    # Store the model after each epoch to compare the performance of them\n",
        "    torch.save(model.state_dict(), os.path.join(models_folder, f\"XLNet4Rec_Movie_{epoch}.pt\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 0 started==============================\n",
            "sum loss 1349.63671875\n",
            "sum loss 1358.9429931640625\n",
            "sum loss 1398.4970703125\n",
            "sum loss 1457.6650390625\n",
            "sum loss 1507.736083984375\n",
            "sum loss 1506.5982666015625\n",
            "sum loss 1501.601318359375\n",
            "sum loss 1497.4395751953125\n",
            "sum loss 1507.4842529296875\n",
            "sum loss 1515.5107421875\n",
            "sum loss 1569.6192626953125\n",
            "sum loss 1569.0867919921875\n",
            "sum loss 1549.2437744140625\n",
            "sum loss 1534.906982421875\n",
            "sum loss 1517.400390625\n",
            "CPU times: user 16min 9s, sys: 7min 41s, total: 23min 51s\n",
            "Wall time: 23min 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxYLQvYYfs4j"
      },
      "source": [
        "model_save_name = 'XLNet4Rec_Movie_4.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNHoqgk43cbu"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0DzsfLU3RqT",
        "outputId": "0eea482c-ea4b-4b7e-f9c1-079d93dbf000"
      },
      "source": [
        "model_save_name = 'XLNet4Rec_Movie_4.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kzz_56x3lNj"
      },
      "source": [
        "# Top products\n",
        "vocab_size = 3706\n",
        "topProducts = [0,1,2,3,4] + tokenizer.convert_tokens_to_ids(list(pdlist.index)[0:vocab_size])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HINrF2hl3mkp"
      },
      "source": [
        "# Probability of each items\n",
        "sum_value = np.sum([x for x in pdlist.values[0:vocab_size]])\n",
        "probs = [0,0,0,0,0,] + [value / sum_value for value in pdlist.values[0:vocab_size]]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay7_ZSLQ3nxk",
        "outputId": "861198d9-69be-4e5a-9e9a-6c9acf52bc39"
      },
      "source": [
        "# Negative samples\n",
        "%%time\n",
        "np.random.seed(12345)\n",
        "neg_samples = []\n",
        "for j in range(0,len(test_dataset)):\n",
        "  samples = np.random.choice(topProducts, 100, replace=False, p=probs)\n",
        "  notinTest = [i for i in samples if i not in test_dataset[j][0][0:torch.where(test_dataset[j][0] == 1)[0]].tolist()]\n",
        "  notinTest = notinTest + test_dataset[j][1].tolist()\n",
        "  neg_samples.append(notinTest)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 27.6 s, sys: 62.6 ms, total: 27.6 s\n",
            "Wall time: 27.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlfnlSnx3yzf",
        "outputId": "ecbfc9a3-d77c-4323-b47e-92243e031e43"
      },
      "source": [
        "# Compute Lengths\n",
        "neg_samples_length = []\n",
        "for i in range(0,len(neg_samples)):\n",
        "  neg_samples_length.append(len(neg_samples[i]))\n",
        "\n",
        "print(np.min(neg_samples_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BYc2uUpVamL",
        "outputId": "37035e07-3ef8-4bd4-ff99-f24a11e21b5d"
      },
      "source": [
        "%%time\n",
        "model = model.to(device)\n",
        "labels = []\n",
        "results = []\n",
        "\n",
        "for idx, batch in enumerate(test_dataloader):\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_labels = batch[1].to(device)\n",
        "    b_target_mapping = batch[2].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      outputs = model(input_ids=b_input_ids, labels=b_labels, target_mapping=b_target_mapping)\n",
        "      logits = outputs[1]\n",
        "    \n",
        "    softmax_logits = torch.softmax(logits[0],dim=1)\n",
        "    softmax_logits = softmax_logits.detach().cpu().numpy()\n",
        "\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    labels.append(label_ids[0])\n",
        "\n",
        "    results.append(softmax_logits)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 45s, sys: 2min 32s, total: 8min 17s\n",
            "Wall time: 8min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd3QmNnsLWYL"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4VPBscSVhWa",
        "outputId": "42fe126f-aa7f-47c1-e9cc-e90e30316811"
      },
      "source": [
        "# Ranking\n",
        "%%time\n",
        "tens = []\n",
        "fives = []\n",
        "ones = []\n",
        "\n",
        "for i in range(0,len(results)):\n",
        "  top_idx = np.argsort(results[i][0][neg_samples[i]])[-10:]\n",
        "  top_values = [neg_samples[i][e] for e in top_idx]\n",
        "  top_values.reverse()\n",
        "  tens.append(top_values)\n",
        "  fives.append(top_values[0:5])\n",
        "  ones.append([top_values[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 57.8 ms, sys: 0 ns, total: 57.8 ms\n",
            "Wall time: 58.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k0hxSCQVjIV"
      },
      "source": [
        "# For HitRate\n",
        "matched_tens = []\n",
        "matched_fives = []\n",
        "matched_ones = []\n",
        "\n",
        "for i in range(0,len(labels)):\n",
        "  matched_tens.append(labels[i][0] in tens[i])\n",
        "  matched_fives.append(labels[i][0] in fives[i])\n",
        "  matched_ones.append(labels[i][0] in ones[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBy4peWoVl2B"
      },
      "source": [
        "# For HitRate\n",
        "matched_tens = []\n",
        "matched_fives = []\n",
        "matched_ones = []\n",
        "\n",
        "for i in range(0,len(labels)):\n",
        "  matched_tens.append(labels[i][0] in tens[i])\n",
        "  matched_fives.append(labels[i][0] in fives[i])\n",
        "  matched_ones.append(labels[i][0] in ones[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7QMNlXpVnkj",
        "outputId": "4ab67a2f-f1ad-412b-f178-9d13e037e3e6"
      },
      "source": [
        "# HitRate\n",
        "print('HR@10:', sum(matched_tens)/len(labels))\n",
        "print('HR@5:', sum(matched_fives)/len(labels))\n",
        "print('HR@1:', sum(matched_ones)/len(labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HR@10: 0.013245033112582781\n",
            "HR@5: 0.009271523178807948\n",
            "HR@1: 0.002980132450331126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SWZ-6_cVpPH"
      },
      "source": [
        "# For NDCG\n",
        "ndcg_tens = []\n",
        "ndcg_fives = []\n",
        "ndcg_ones = []\n",
        "\n",
        "for i in range(0,len(labels)):\n",
        "  for j in range(0,len(tens[i])):\n",
        "    if labels[i] == tens[i][j]:\n",
        "      ndcg_tens.append(1/np.log2(j+2))\n",
        "    else:\n",
        "      ndcg_tens.append(0)\n",
        "  for j in range(0,len(fives[i])):\n",
        "    if labels[i] == fives[i][j]:\n",
        "      ndcg_fives.append(1/np.log2(j+2))\n",
        "    else:\n",
        "      ndcg_fives.append(0)\n",
        "  for j in range(0,len(ones[i])):\n",
        "    if labels[i] == ones[i][j]:\n",
        "      ndcg_ones.append(1/np.log2(j+2))\n",
        "    else:\n",
        "      ndcg_ones.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9hG21sAVrCi",
        "outputId": "af8d84e6-ebb2-49bd-c797-89a5dd60f650"
      },
      "source": [
        "# NDCG\n",
        "print('NDCG@10:', np.mean(ndcg_tens))\n",
        "print('NDCG@5:', np.mean(ndcg_fives))\n",
        "print('NDCG@1:', np.mean(ndcg_ones))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NDCG@10: 0.0007509409774537978\n",
            "NDCG@5: 0.0012512977524511103\n",
            "NDCG@1: 0.002980132450331126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvhWRpEaVsm_"
      },
      "source": [
        "# For MRR\n",
        "rr = []\n",
        "\n",
        "for i in range(0,len(labels)):\n",
        "  for j in range(0,len(tens[i])):\n",
        "    if labels[i] == tens[i][j]:\n",
        "      rr.append(1/(j+1))\n",
        "    else:\n",
        "      rr.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld9GEFufVuC2",
        "outputId": "742a4646-ac63-4973-9ed7-b0e99a1e00e1"
      },
      "source": [
        "# MRR\n",
        "print('MRR', np.mean(rr)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MRR 0.0005757253232418795\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}